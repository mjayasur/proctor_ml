<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Login</title>
        <link rel="icon" href="https://images.vexels.com/media/users/3/157893/isolated/preview/d6f4e679138673eb3223362c70ecf7ce-check-mark-tick-icon-by-vexels.png">

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
        <link href="login.css" rel="stylesheet">
            <!-- Insert these scripts at the bottom of the HTML, but before you use any Firebase services -->

        <!-- Firebase App (the core Firebase SDK) is always required and must be listed first -->
        <script src="https://www.gstatic.com/firebasejs/7.14.1/firebase-app.js"></script>

        <!-- If you enabled Analytics in your project, add the Firebase SDK for Analytics -->
        <script src="https://www.gstatic.com/firebasejs/7.14.1/firebase-analytics.js"></script>

        <!-- Add Firebase products that you want to use -->
        <script src="https://www.gstatic.com/firebasejs/7.14.1/firebase-auth.js"></script>
        <script src="https://www.gstatic.com/firebasejs/7.14.1/firebase-firestore.js"></script>
        <script src="camvas.js"></script>
	    	<script src="pico.js"></script>
        <script src="lploc.js"></script>
        <script src = "https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js" ></script>

        <meta http-equiv="X-UA-Compatible" content="chrome=1">
        
    </head>
    <body class = "text-center">
        <div class=" mx-auto container mt-5  col-6">
            <img height=150 width=150 src="randomcheck.png">
            <div id="timer_div"></div>
            <div id="clarifications_div"></div>
            
            <p class = "h4">You are now Testing. Remember, academic dishonesty is unfair for you peers and hurts everyone.</p>
            
            <p class = "h4">Make sure that you are in frame!</p>
            <button onclick="takeBathroomBreak()" id="bathroom_button" class = "btn btn-primary mb-3">Take Bathroom Break</button>
            
        </div>

        <canvas width=640 height=480></canvas>   
        <script src="https://unpkg.com/react@16/umd/react.development.js" crossorigin></script>
        <script src="https://unpkg.com/react-dom@16/umd/react-dom.development.js" crossorigin></script>
        <script src="./timer.js"></script>
        <script src="./clarifications.js"></script>
        <script>
          findGetParameter = (parameterName) => {
    var result = null,
      tmp = [];
    location.search
      .substr(1)
      .split("&")
      .forEach(function (item) {
      tmp = item.split("=");
      if (tmp[0] === parameterName) result = decodeURIComponent(tmp[1]);
      });
    return result;
  }



		if (localStorage.getItem("sid") === null) {
			window.location.assign("/login.html?exam_id=" + findGetParameter("exam_id"))
		}
          const socket = io('https://proctor.ml:4001/');
          socket.emit("status update", localStorage.getItem("sid"), "connected", findGetParameter("exam_id"))
          var bathroom = false;
          function takeBathroomBreak() {
            bathroom = true;
            document.getElementById("bathroom_button").onclick = endBathroomBreak
            document.getElementById("bathroom_button").textContent = "End Bathroom Break"
            socket.emit("status update", localStorage.getItem("sid"), "bathroom_break", findGetParameter("exam_id"))
          }
          function endBathroomBreak() {
            bathroom = false;
            document.getElementById("bathroom_button").onclick = takeBathroomBreak
            document.getElementById("bathroom_button").textContent = "Take Bathroom Break"
            socket.emit("status update", localStorage.getItem("sid"), "connected", findGetParameter("exam_id"))
          }
          document.addEventListener('DOMContentLoaded', function() {
          if (!Notification) {
            alert('Desktop notifications not available in your browser. Try Chromium.');
            return;
          }

          if (Notification.permission !== 'granted')
            Notification.requestPermission();
          });


        function notifyMe() {

          if (Notification.permission !== 'granted') {

            Notification.requestPermission();
          }
          else {
            var notification = new Notification('Proctor.me', {
            icon: 'randomcheck.png',
            body: 'Make sure your face is in frame and the blue circle surrounds it.',
            });

          }
          }
          function notifyMeMult() {

            if (Notification.permission !== 'granted') {

              Notification.requestPermission();
            }
            else {
              var notification = new Notification('Proctor.me', {
              icon: 'randomcheck.png',
              body: 'Only one person is allowed in frame!',
              });

            }
            }
          

        var initialized = false;
        var out_of_frame_count = 0;
        var two_frame_notifed = 0
        var two_frame_count = 0
        var num_notifs = 0;
        function button_callback() {
                /*
            (0) check whether we're already running face detection
          */
          if(initialized)
            return; // if yes, then do not initialize everything again
          /*
            (1) initialize the pico.js face detector
          */
          var update_memory = pico.instantiate_detection_memory(5); // we will use the detecions of the last 5 frames
          var facefinder_classify_region = function(r, c, s, pixels, ldim) {return -1.0;};
          var cascadeurl = 'https://raw.githubusercontent.com/nenadmarkus/pico/c2e81f9d23cc11d1a612fd21e4f9de0921a5d0d9/rnt/cascades/facefinder';
          fetch(cascadeurl).then(function(response) {
            response.arrayBuffer().then(function(buffer) {
              var bytes = new Int8Array(buffer);
              facefinder_classify_region = pico.unpack_cascade(bytes);
              console.log('* facefinder loaded');
            })
          })
          /*
            (2) initialize the lploc.js library with a pupil localizer
          */
          var do_puploc = function(r, c, s, nperturbs, pixels, nrows, ncols, ldim) {return [-1.0, -1.0];};
          //var puplocurl = '../puploc.bin';
          var puplocurl = 'https://f002.backblazeb2.com/file/tehnokv-www/posts/puploc-with-trees/demo/puploc.bin'
          fetch(puplocurl).then(function(response) {
            response.arrayBuffer().then(function(buffer) {
              var bytes = new Int8Array(buffer);
              do_puploc = lploc.unpack_localizer(bytes);
              console.log('* puploc loaded');
            })
          })
          /*
            (3) get the drawing context on the canvasand define a function to transform an RGBA image to grayscale
          */
          var ctx = document.getElementsByTagName('canvas')[0].getContext('2d');
          function rgba_to_grayscale(rgba, nrows, ncols) {
            var gray = new Uint8Array(nrows*ncols);
            for(var r=0; r<nrows; ++r)
              for(var c=0; c<ncols; ++c)
                // gray = 0.2*red + 0.7*green + 0.1*blue
                gray[r*ncols + c] = (2*rgba[r*4*ncols+4*c+0]+7*rgba[r*4*ncols+4*c+1]+1*rgba[r*4*ncols+4*c+2])/10;
            return gray;
          }
          /*
            (4) this function is called each time a video frame becomes available
          */
          var processfn = function(video, dt) {
            // render the video frame to the canvas element and extract RGBA pixel data
            ctx.drawImage(video, 0, 0);
            var rgba = ctx.getImageData(0, 0, 640, 480).data;
            // prepare input to `run_cascade`
            image = {
              "pixels": rgba_to_grayscale(rgba, 480, 640),
              "nrows": 480,
              "ncols": 640,
              "ldim": 640
            }
            params = {
              "shiftfactor": 0.1, // move the detection window by 10% of its size
              "minsize": 100,     // minimum size of a face
              "maxsize": 1000,    // maximum size of a face
              "scalefactor": 1.1  // for multiscale processing: resize the detection window by 10% when moving to the higher scale
            }
            // run the cascade over the frame and cluster the obtained detections
            // dets is an array that contains (r, c, s, q) quadruplets
            // (representing row, column, scale and detection score)
            dets = pico.run_cascade(image, facefinder_classify_region, params);
            dets = update_memory(dets);
            dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
            // draw detections
            for(i=0; i<dets.length; ++i)
              // check the detection score
              // if it's above the threshold, draw it
              // (the constant 50.0 is empirical: other cascades might require a different one)
              if(dets[i][3]>50.0)
              {
                if (i == 1) {
                  two_frame_count++;
                  if (two_frame_count > 100 && two_frame_notifed == 0 && !bathroom) {
                    socket.emit("status update", localStorage.getItem("sid"), "two_in_frame", findGetParameter("exam_id"))
                    two_frame_notifed++;
                    notifyMeMult()
                  }
                }
                var r, c, s;
                //
                ctx.beginPath();
                ctx.arc(dets[i][1], dets[i][0], dets[i][2]/2, 0, 2*Math.PI, false);
                ctx.lineWidth = 3;
                ctx.strokeStyle = 'blue';
                // console.log("Face In Frame");
                if (num_notifs > 0 && two_frame_count < 100 && !bathroom) {
                    socket.emit("status update", localStorage.getItem("sid"), "connected", findGetParameter("exam_id"))
                  }                
                num_notifs = 0
                out_of_frame_count = 0
                ctx.stroke();
                //
                // find the eye pupils for each detected face
                // starting regions for localization are initialized based on the face bounding box
                // (parameters are set empirically)
                // first eye
                r = dets[i][0] - 0.075*dets[i][2];
                c = dets[i][1] - 0.175*dets[i][2];
                s = 0.35*dets[i][2];
                [r, c] = do_puploc(r, c, s, 63, image)
                if(r>=0 && c>=0)
                {
                  ctx.beginPath();
                  ctx.arc(c, r, 1, 0, 2*Math.PI, false);
                  ctx.lineWidth = 3;
                  ctx.strokeStyle = 'red';
                  ctx.stroke();
                }
                // second eye
                r = dets[i][0] - 0.075*dets[i][2];
                c = dets[i][1] + 0.175*dets[i][2];
                s = 0.35*dets[i][2];
                [r, c] = do_puploc(r, c, s, 63, image)
                if(r>=0 && c>=0)
                {
                  ctx.beginPath();
                  ctx.arc(c, r, 1, 0, 2*Math.PI, false);
                  ctx.lineWidth = 3;
                  ctx.strokeStyle = 'red';
                  ctx.stroke();
                }
              } else if (!bathroom) {

                out_of_frame_count += 1

                if (out_of_frame_count >= 100) {
                  notifyMe();
                  out_of_frame_count = 0;
                  num_notifs += 1;
                  if (num_notifs > 0) {
                    socket.emit("status update", localStorage.getItem("sid"), "not_in_frame", findGetParameter("exam_id"))
                  }
                }
              }
          }
          /*
            (5) instantiate camera handling (see https://github.com/cbrandolino/camvas)
          */
          var mycamvas = new camvas(ctx, processfn);
          /*
            (6) it seems that everything went well
          */
          initialized = true;
            }
          button_callback();
        
        </script>

        <!-- <div class="container col-6 d-flex h-100">
                <div class="mx-auto text-center justify-content-center align-self-center"> -->


                <!-- </div>
        </div> -->
    </body>
</html>